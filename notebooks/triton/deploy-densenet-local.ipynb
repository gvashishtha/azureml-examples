{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy to Triton Inference Server locally\n",
        "\n",
        "description: (preview) deploy an image classification model trained on densenet locally via Triton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please note that this Public Preview release is subject to the [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Workspace.create(name='default', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='azureml-examples')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ws"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download model\n",
        "\n",
        "It's important that your model have this directory structure for Triton Inference Server to be able to load it. [Read more about the directory structure that Triton expects](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/model_repository.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully downloaded model: densenet_onnx\n",
            "successfully downloaded model: bidaf-9\n"
          ]
        }
      ],
      "source": [
        "import git\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# get the root of the repo\n",
        "prefix = Path(git.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
        "\n",
        "# Enables us to import helper functions as Python modules\n",
        "path_to_insert = prefix.joinpath(\"code\", \"deployment\", \"triton\").__str__()\n",
        "if path_to_insert not in sys.path:\n",
        "    sys.path.insert(1, path_to_insert)\n",
        "\n",
        "from model_utils import download_triton_models, delete_triton_models\n",
        "\n",
        "\n",
        "download_triton_models(prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register model\n",
        "\n",
        "A registered model is a logical container stored in the cloud, containing all files located at `model_path`, which is associated with a version number and other metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model densenet-onnx-example\n",
            "Model(workspace=Workspace.create(name='default', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='azureml-examples'), name=densenet-onnx-example, id=densenet-onnx-example:508, version=508, tags={'area': 'Image classification', 'type': 'classification'}, properties={})\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model_path = prefix.joinpath(\"models\")\n",
        "\n",
        "model = Model.register(\n",
        "    model_path=model_path,\n",
        "    model_name=\"densenet-onnx-example\",\n",
        "    tags={\"area\": \"Image classification\", \"type\": \"classification\"},\n",
        "    description=\"Image classification trained on Imagenet Dataset\",\n",
        "    workspace=ws,\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy webservice\n",
        "\n",
        "In this case we deploy to the local compute, but for other options, see [our documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where?tabs=azcli)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CondaDependencies' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1402b8dd7674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dockerfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"notebooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"docker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dockerfile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconda_dependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCondaDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_managed_dependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/opt/miniconda/bin/python'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CondaDependencies' is not defined"
          ]
        }
      ],
      "source": [
        "from azureml.core.webservice import LocalWebservice\n",
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.model import InferenceConfig\n",
        "from random import randint\n",
        "\n",
        "service_name = \"triton-densenet-onnx-local\" + str(randint(10000, 99999))\n",
        "env = Environment(\"triton-example\")\n",
        "env.docker.base_image = None\n",
        "env.docker.base_dockerfile=prefix.joinpath(\"notebooks\", \"triton\", \"docker\", \"Dockerfile\")\n",
        "env.python.conda_dependencies=CondaDependencies()\n",
        "env.python.user_managed_dependencies=True\n",
        "env.python.interpreter_path='/opt/miniconda/bin/python'\n",
        "env.inferencing_stack_version='latest'\n",
        "\n",
        "\n",
        "inference_config = InferenceConfig(\n",
        "    # this entry script is where we dispatch a call to the Triton server\n",
        "    entry_script=\"score_densenet.py\",\n",
        "    source_directory=prefix.joinpath(\"code\", \"deployment\", \"triton\"),\n",
        "    environment=env,\n",
        ")\n",
        "\n",
        "config = LocalWebservice.deploy_configuration(port=6789)\n",
        "\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=config,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the webservice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "headers = {\"Content-Type\": \"application/octet-stream\"}\n",
        "\n",
        "data_file = prefix.joinpath(\"data\", \"raw\", \"images\", \"peacock.jpg\")\n",
        "test_sample = open(data_file, \"rb\").read()\n",
        "resp = requests.post(service.scoring_uri, data=test_sample, headers=headers)\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete the webservice and the downloaded model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "service.delete()\n",
        "delete_triton_models(prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Next steps\n",
        "\n",
        "Try changing the deployment configuration to [deploy to Azure Kubernetes Service](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-azure-kubernetes-service?tabs=python) for higher availability and better scalability."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "Python 3.7.7 64-bit ('azureml': conda)",
      "display_name": "Python 3.7.7 64-bit ('azureml': conda)",
      "metadata": {
        "interpreter": {
          "hash": "53514593536e52de022f29ef618678eddccd581b6db5dc532e9838fb19203af5"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "name": "deploy-densenet-local",
    "task": "Use the high-performance Triton Inference Server with Azure Machine Learning"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}